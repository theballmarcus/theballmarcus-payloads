#!/usr/bin/env python3
"""
Fuzz Helper Tool

Converts a HTTP(S) request file into fuzzing requests.
and optionally performs character-by-character fuzzing.
"""
import argparse
import json
import os
import string
import sys
from collections import Counter
from typing import Any, Dict, List, Tuple, Union, Generator, Optional
from unittest import result
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import statistics
import importlib.util
import re

VERBOSE = False
MAX_WORKERS = 10  # Default max workers for ThreadPoolExecutor
MAX_CONCURRENT_REQUESTS = 300  # Max concurrent requests per token
DEFAULT_WORDLISTS = {
    'rockyou' : '~/wordlist/rockyou.txt',
    'directories' : '~/wordlist/directory-list-2.3-small.txt',
    'usernames' : '~/wordlist/usernames.txt',
}
SAFE_CHARS = set(string.ascii_letters + string.digits + '-_')

## ----- Response Analysis ----- ### 

def find_successful_wordlist_payload(responses, deviation_threshold=1):
    global VERBOSE
    """
    Identify the payload (e.g., password) that succeeded in a wordlist attack.
    Criteria (in order):
    1. HTTP status code in 200-299 (success)
    2. show_response True (passed filters, e.g. show_string)
    3. Longest deviation from majority response length,
       only if deviation is significant (greater than deviation_threshold)
    
    Returns the payload string or None if not found.
    """
    if not responses:
        return None

    lengths = [r.get('chars', 0) for r in responses]
    if not lengths:
        return None

    most_common_len, _ = Counter(lengths).most_common(1)[0]
    deviations = [(abs(r['chars'] - most_common_len), r) for r in responses]
    deviations.sort(reverse=True, key=lambda x: x[0])

    max_deviation, best_response = deviations[0]
    if VERBOSE:
        print(f"Max deviation: {max_deviation}, Threshold: {deviation_threshold}")
    if max_deviation > deviation_threshold:
        return best_response.get('payload')

    return None

def analyze_responses(responses, time_based=False):
    """
    Unified analysis for fuzzing responses.
    - If time_based: delegate to timing analysis
    - If payloads are multi-char (wordlist), use dedicated finder
    - Else fallback to char-based analysis
    """
    # Detect multi-char payloads: any payload length > 1
    # multi = any(len(r.get('payload', '')) > 1 for r in responses)
    # if multi and not time_based:
    #     return find_successful_wordlist_payload(responses)

    # existing char-based logic
    if time_based:
        # ... existing time-based code ...
        from statistics import mean
        stats = {}
        for r in responses:
            c = r.get('payload', '')
            if len(c) != 1: continue
            stats.setdefault(c, []).append(r['response_time'])
        if not stats: return None
        avg = {c: sum(t)/len(t) for c, t in stats.items()}
        global_mean = mean(avg.values())
        best = max(avg.items(), key=lambda x: x[1] - global_mean)
        if (best[1] - global_mean) > global_mean * 0.35:
            return best[0]
        return None
    else:
        # existing content-deviation logic
        patterns = Counter((r['chars'], r['words'], r.get('lines',0)) for r in responses)
        majority, _ = patterns.most_common(1)[0]
        deviations = []
        for r in responses:
            if r.get('code', 0) < 400:
                patt = (r['chars'], r['words'], r.get('lines',0))
                if patt != majority:
                    dev = sum(abs(a-b) for a, b in zip(patt, majority))
                    deviations.append((dev, r))
        if not deviations:
            return None
        # pick payload with max deviation
        best = max(deviations, key=lambda x: x[0])[1]
        return best.get('payload')

## ----- Helper Functions ----- ##

def load_dynamic_script(script_path: str):
    """Load and return a module from the given script path"""
    if not os.path.exists(script_path):
        return None
    
    module_name = os.path.splitext(os.path.basename(script_path))[0]
    spec = importlib.util.spec_from_file_location(module_name, script_path)
    if not spec or not spec.loader:
        return None
    
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module

def execute_dynamic_script(script_module, data: Dict[str, Any]):
    global VERBOSE
    """Execute the dynamic script if conditions are met"""
    if not script_module:
        return False
    
    try:
        # Check if the script has a condition function
        if hasattr(script_module, 'condition'):
            condition_met = script_module.condition(data)
            if not condition_met and VERBOSE:
                print(f"Skipping script {script_module.__name__} due to condition not met.")
                return False
        
        # Execute the main function if it exists
        if hasattr(script_module, 'execute'):
            script_module.execute(data)
            if VERBOSE:
                print(f"Executed dynamic script: {script_module.__name__}")
            return True
        
        return False
    except Exception as e:
        print(f"Error executing dynamic script: {str(e)}")
        return False

def to_ansi_c_quoted_string(s: str) -> str:
    """Convert string to ANSI C quoted string for shell."""
    parts, i = [], 0
    while i < len(s):
        c = s[i]
        if c == '\r' and i + 1 < len(s) and s[i+1] == '\n':
            parts.append('\\x0d\\x0a'); i += 2; continue
        if c == '\n':
            parts.append('\\x0d\\x0a'); i += 1; continue
        if 32 <= ord(c) <= 126 and c not in "\\'":
            parts.append(c)
        else:
            if c == '\\': parts.append('\\\\')
            elif c == "'": parts.append("\\'")
            else: parts.append(f"\\x{ord(c):02x}")
        i += 1
    return "$'" + ''.join(parts) + "'"

def parse_request_file(path: str) -> Tuple[str, str, Dict[str, str], str]:
    """Parse Burp HTTP request file into method, path, headers, body."""
    with open(path, 'r') as f:
        lines = f.read().splitlines()
    method, req_path, _ = lines[0].split(maxsplit=2)
    headers, body_lines, in_body = {}, [], False
    for line in lines[1:]:
        if not in_body and not line.strip():
            in_body = True
            continue
        if in_body:
            body_lines.append(line)
        else:
            if ':' in line:
                k, v = line.split(':', 1)
                headers[k.strip()] = v.strip()

    base_url = headers.get('Host', '').strip()

    body = '\r\n'.join(body_lines)
    return method, req_path, headers, body, base_url

def parse_response():
    """Parse response from output."""
    raise NotImplementedError("This function is not implemented yet. It should parse the output and return structured data.")

## ----- Setup ----- ##

def parse_mode_options(raw_options: str) -> Dict[str, Any]:
    """
    Parse mode options from a string like 'set=alphanum,append=True'.
    Returns a dictionary of options.
    """
    options = {}
    for opt in raw_options.split(','):
        if '=' in opt:
            key, value = opt.split('=', 1)
            value = value.strip()
            if value.lower() == 'true':
                options[key.strip()] = True
            elif value.lower() == 'false':
                options[key.strip()] = False
            else:
                options[key.strip()] = value.strip()
        else:
            options[opt.strip()] = True

    return options

def parse_fuzz_tokens(text: str) -> List[Dict[str, Any]]:
    # Regex pattern to find fuzz tokens
    fuzz_pattern = re.compile(
        r'(F(?P<num>\d+)Z(?P<mode>[A-Z]+)(?::(?P<options>.*?))?:Z)'
    )

    results = []
    for match in fuzz_pattern.finditer(text):
        full_token = match.group(1)
        num = int(match.group("num"))
        mode = match.group("mode")
        options_raw = match.group("options") or ""

        # Start with default empty dict
        options: Dict[str, Any] = {}

        # Mode-specific option parsing
        if mode == "W":  # Wordlist mode
            # Match to default wordlist or custom wordlist
            options = {
                "wordlist": options_raw.strip()
            }

            for key, default in DEFAULT_WORDLISTS.items():
                if options_raw.strip() == key:
                    options["wordlist"] = os.path.expanduser(default)
                    break

        elif mode == "I":  # Integer guessing
            options = parse_mode_options(options_raw)

            # Defaults
            options.setdefault("start", "0")
            options.setdefault("step", "1")
            options.setdefault("end", "100")  # Default end value
            options.setdefault("follow", False)
            options.setdefault("padding", 0)

        elif mode == "G":  # Character guessing (ZG:set=...)
            options = parse_mode_options(options_raw)
            options.setdefault("set", "alphanum")
            options.setdefault("append", False)

        else:
            # Fallback for unknown modes â€” raw options as key-value if possible
            for opt in options_raw.split(","):
                if "=" in opt:
                    key, value = opt.split("=", 1)
                    options[key.strip()] = value.strip()
                elif opt.strip():
                    options[opt.strip()] = True

        results.append({
            "token": full_token,
            "index": num,
            "mode": mode,
            "options": options
        })

    return results

def build_custom_parameters(method: str, path: str, headers: Dict[str, str], body: str, args: argparse.Namespace) -> Dict[str, Any]:
    """Build custom parameters for python."""
    headers_fuzz = parse_fuzz_tokens(json.dumps(headers))
    body_fuzz = parse_fuzz_tokens(body)
    path_fuzz = parse_fuzz_tokens(path)

    full_fuzz = headers_fuzz + body_fuzz + path_fuzz

    params = {
        'method': method,
        'headers': headers,
        'body': body,
        'base_url': args.base_url,
        'path': path,
        'response_filters' : {
            'hide_length': args.hide_length,
            'show_length': args.show_length,
            'show_code': args.show_code,
            'hide_code': args.hide_code,
            'show_string': args.show_string,
            'hide_string': args.hide_string
        },
        'FUZZ' : full_fuzz
    }
    return params

## ----- Fireing ----- ##

class TokenGenerator:
    def __init__(self, token_spec: Dict[str, Any]):
        self.token = token_spec['token']
        self.mode = token_spec['mode']
        self.options = token_spec.get('options', {})
        
        # State tracking
        self.guessed_length = 0  # For follow=True tokens
        self.current_value = None  # For I mode tokens
        self.current_string = ""  # For G mode tokens
        self.wordlist_index = 0  # For W mode tokens
        
        # Initialize based on mode
        if self.mode == 'I':
            self.start = int(self.options.get('start', 1))
            self.end = int(self.options.get('end', 100))
            self.step = int(self.options.get('step', 1))
            self.current_value = self.start
            self.follow = self.options.get('follow', False)
            self.padding = int(self.options.get('padding', 0))
            self.stop_at_end = self.options.get('stop_at_end', False)
            
        elif self.mode == 'W':
            self.wordlist = self.options['wordlist']
            self.words = self._load_wordlist()
            
        elif self.mode == 'G':
            self.charset = self._get_charset()
            self.char_index = 0

    def _get_charset(self) -> str:
        """Get character set for G mode"""
        charset = self.options.get('set', 'alphanum')
        if charset == 'alphanum': 
            return string.ascii_letters + string.digits + '-_'
        elif charset == 'hex': 
            return string.hexdigits.lower()
        elif charset == 'numeric': 
            return string.digits
        return charset

    def _load_wordlist(self) -> list:
        """Load wordlist from file"""
        try:
            with open(self.wordlist, 'r', errors='replace') as f:
                return [line.strip() for line in f if line.strip()]
        except Exception:
            return []

    def get_payload(self) -> str:
        """Generate the next payload based on token mode"""
        if self.mode == 'I':
            if self.follow:
                return str(self.guessed_length).rjust(self.padding, '0')
            else:
                payload = str(self.current_value)
                if self.current_value <= self.end:
                    self.current_value += self.step
                elif self.current_value > self.end:
                    if self.stop_at_end:
                        return ""
                    else:
                        self.current_value = self.start
                return payload.rjust(self.padding, '0')
                
        elif self.mode == 'W':
            if self.wordlist_index < len(self.words):
                payload = self.words[self.wordlist_index]
                self.wordlist_index += 1
                return payload
            return ""
            
        elif self.mode == 'G':
            if self.char_index < len(self.charset):
                char = self.charset[self.char_index]
                self.char_index += 1
                if self.options.get('append', False):
                    return self.current_string + char
                else:
                    return char
            return ""
        
        return ""

    def advance_position(self):
        """Advance to next character position for G mode"""
        if self.mode == 'G' and self.char_index >= len(self.charset):
            self.current_string += "?"
            self.char_index = 0

    def confirm_guess(self, guess: str):
        """Update state with successful guess"""
        if self.mode == 'G':
            self.current_string = guess
            self.char_index = 0

def fire_requests(parameters: Dict[str, Any], time_based: bool = False) -> List[Dict[str, Any]]:
    """
    Fire threaded fuzzing requests for both stateful and non-stateful tokens.
    - If any non-stateful payload triggers the filters, exit early.
    - If no filters are provided, exhaust all non-stateful payloads, then pick the one
      whose response length deviates most from the majority.
    - For stateful (G-mode) tokens, exit as soon as no new character can be distinguished,
      returning the final assembled string.
    """
    from concurrent.futures import ThreadPoolExecutor, as_completed

    method          = parameters['method']
    headers         = parameters['headers']
    body            = parameters['body']
    base_url        = parameters['base_url']
    path            = parameters['path']
    req_url         = f"{base_url}{path}"
    filters         = parameters.get('response_filters', {}) or {}
    fuzz_tokens     = parameters.get('FUZZ', [])
    script_modules  = parameters.get('script_modules', [])
    no_postprocess  = parameters.get('no_postprocess', False)

    # Initialize generators for each FUZZ token
    token_generators = {}
    for spec in fuzz_tokens:
        try:
            token_generators[spec['token']] = TokenGenerator(spec)
        except Exception as e:
            print(f"Error creating token generator: {e}")
            return []

    # Categorize tokens
    stateful      = [t for t, g in token_generators.items() if g.mode == 'G']
    non_stateful  = [t for t, g in token_generators.items() if g.mode != 'G']
    follow_tokens = {t: g for t, g in token_generators.items() if g.mode == 'I' and g.follow}

    results = []
    all_nonstateful_resps = []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # If there are no stateful tokens, first exhaust all non-stateful payloads
        if not stateful:
            if no_postprocess:
                # Run in parallel but discard results immediately
                futures = []
                concurrent_requests = 0
                while True:
                    repl = {t: token_generators[t].get_payload() for t in non_stateful}
                    if any(val == "" for val in repl.values()):
                        break

                    new_h = {k: v for k, v in headers.items()}
                    for k, v in new_h.items():
                        for tok, val in repl.items():
                            v = v.replace(tok, val)
                        new_h[k] = v
                    new_b = body
                    for tok, val in repl.items():
                        new_b = new_b.replace(tok, val)

                    fut = executor.submit(
                        send_request,
                        req_url, method, new_h, new_b,
                        filters,
                        payload=str(repl),
                        script_modules=script_modules,
                        no_postprocess=True
                    )
                    futures.append(fut)
                    concurrent_requests += 1
                    if concurrent_requests >= MAX_CONCURRENT_REQUESTS:
                        # Wait for some futures to complete before submitting more
                        if VERBOSE:
                            print(f"Waiting for {concurrent_requests} concurrent requests to complete...")
                        concurrent_requests = 0
                        for fut in as_completed(futures):
                            try:
                                _ = fut.result()  # Trigger execution and free result
                            except Exception as e:
                                if VERBOSE:
                                    print(f"Request error: {e}")
                return []  # done
            else:
                # Store futures and results when postprocessing is needed
                nonstateful_futures: Dict = {}

                while True:
                    repl = {t: token_generators[t].get_payload() for t in non_stateful}
                    if any(val == "" for val in repl.values()):
                        break

                    new_h = {k: v for k, v in headers.items()}
                    for k, v in new_h.items():
                        for tok, val in repl.items():
                            v = v.replace(tok, val)
                        new_h[k] = v
                    new_b = body
                    for tok, val in repl.items():
                        new_b = new_b.replace(tok, val)

                    fut = executor.submit(
                        send_request,
                        req_url, method, new_h, new_b,
                        filters,
                        payload=str(repl),
                        script_modules=script_modules,
                        no_postprocess=False
                    )
                    nonstateful_futures[fut] = repl

                for fut in as_completed(nonstateful_futures):
                    repl = nonstateful_futures[fut]
                    resp = fut.result()[0]
                    all_nonstateful_resps.append((repl, resp))
                    results.append(resp)
                    if any(v is not None for v in filters.values()) and resp.get('show_response'):
                        if VERBOSE:
                            print(f"\nðŸ”‘ Found matching non-stateful payload: {repl}")

        # Otherwise, or after exhausting non-stateful, handle stateful character guessing
        while stateful:
            # update followâ€‘length tokens
            for t, g in follow_tokens.items():
                g.guessed_length = max(len(token_generators[s].current_string) for s in stateful)

            futures: Dict = {}
            # submit one request per candidate character per token
            for t in stateful:
                gen = token_generators[t]
                if len(gen.current_string) >= 50:
                    continue
                for idx, ch in enumerate(gen.charset):
                    if gen.options.get('append', False) == True:
                        candidate = gen.current_string + ch
                    else:
                        candidate = ch

                    repl = {x: token_generators[x].get_payload() for x in non_stateful}
                    repl[t] = candidate

                    new_h = {k: v for k, v in headers.items()}
                    for k, v in new_h.items():
                        for tok, val in repl.items():
                            v = v.replace(tok, val)
                        new_h[k] = v
                    new_b = body
                    for tok, val in repl.items():
                        new_b = new_b.replace(tok, val)

                    fut = executor.submit(
                        send_request,
                        req_url, method, new_h, new_b,
                        filters,
                        idx=idx, payload=candidate,
                        script_modules=script_modules
                    )
                    futures[fut] = (t, ch)

            # collect responses
            grouped = {t: [] for t in stateful}
            for fut in as_completed(futures):
                resp = fut.result()[0]
                t, ch = futures[fut]
                resp.update({'candidate_char': ch, 'token': t})
                grouped[t].append(resp)
                results.append(resp)

            # analyze and update each stateful token
            progress = False
            for t in list(stateful):
                grp = grouped.get(t, [])
                if not grp:
                    continue
                probable = analyze_responses(grp, time_based)
                gen = token_generators[t]
                if probable:
                    if gen.options.get('append', False):
                        gen.current_string = probable
                    else:
                        gen.current_string = gen.current_string + probable
                    print(f"\nâœ… Token '{t}' extended to: {gen.current_string}")
                    progress = True
                else:
                    # no distinguishing char â†’ final value reached
                    final_val = gen.current_string
                    print(f"\nðŸ Token '{t}' final value: {final_val}")
                    stateful.remove(t)

            if not progress:
                break  # no further progress

    # Postâ€processing for pure nonâ€stateful when no filters were provided all(v is None for v in filters.values()) and 
    if not stateful and all_nonstateful_resps:
        # check for filters
        if any(v is not None for v in filters.values()):
            matches = [resp for _, resp in all_nonstateful_resps if resp.get('show_response')]
            if VERBOSE:
                print(f"Found {len(matches)} matching non-stateful payloads with filters applied.")
            if matches and len(matches) == 1:
                print(f"\nðŸ”‘ Found only one matching non-stateful payload: {matches[0].get('payload')}")
                return matches

        # Extract just the response dicts
        flat_resps = [resp for _, resp in all_nonstateful_resps]

        # Delegate to our unified analyzer (will pick the 2xx or bestâ€‘length payload)
        successful = find_successful_wordlist_payload(flat_resps)
        
        if successful:
            # Find and return only the matching response(s)
            matched = [r for r in flat_resps if r.get('payload') == successful]
            print(f"\\nðŸ”‘ Wordlist attack succeeded with payload: {successful}")
            return matched
        else:
            print("\\nâš ï¸ No successful payload found in wordlist attack.")

    return results

def send_request(
    req_url: str, 
    method: str, 
    headers: Dict[str, str], 
    body: str, 
    filters: Dict[str, Any],
    idx: int = 0,
    payload: str = "",
    script_modules: Optional[List[Any]] = None,
    print_response: bool = False,
    no_postprocess: bool = False
) -> Optional[Tuple[bool, Dict[str, Any]]]:
    global VERBOSE
    """Send a request and return filter status + summary."""

    try:
        response = requests.request(
            method, req_url, headers=headers, data=body, timeout=10
        )

        if print_response:
            print(f"{response.text}")

        show_response = True
        if VERBOSE:
            print(f"ðŸ”¥ Sending request #{idx + 1} to {req_url} with payload: {payload}, idx: {idx}")
        # Apply response filters
        for key, filter_val in filters.items():
            if filter_val is None:
                continue
                
            response_text = response.text
            if key == 'hide_length' and response_text:
                if len(response_text) == filter_val:
                    show_response = False
            elif key == 'show_length' and response_text:
                if len(response_text) != filter_val:
                    show_response = False
            elif key == 'show_code' and response.status_code != filter_val:
                show_response = False
            elif key == 'hide_code' and response.status_code == filter_val:
                show_response = False
            elif key == 'show_string' and filter_val not in response_text:
                show_response = False
            elif key == 'hide_string' and filter_val in response_text:
                show_response = False

        if no_postprocess:
            if show_response:
                print(f"ðŸ” Response for payload passed filters {payload}")
                print(f"\n\n\n\n\n\n{response.text}\n\n\n\n\n")
                print(f"ðŸ”¥ Request #{idx + 1} to {req_url} with payload: {payload}, idx: {idx}")
                print(f"#----------------------------------#")
                print(f"Response code: {response.status_code}")
            return


        summary = {
            'code': response.status_code,
            'chars': len(response.text),
            'response_time': response.elapsed.total_seconds(),
            'payload': payload,
            'words': len(response.text.split()),
            'idx' : idx,
            'show_response': show_response
        }


        if script_modules:
            for script_module in script_modules:
                execute_dynamic_script(script_module, summary)
        return [summary]
    
    except requests.RequestException as e:
        print(f"Request failed: {e}")
        if no_postprocess:
            return
        else:
            return [{
                'code': 500, 
                'chars': 0, 
                'words': 0, 
                'lines': 0, 
                'response_time': 0,
                'payload': body,
                'show_response': False
            }]
    
def main() -> None:
    global VERBOSE
    global MAX_WORKERS
    global MAX_CONCURRENT_REQUESTS

    parser = argparse.ArgumentParser(description="Convert request file to fuzzing tool.")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    run_parser = subparsers.add_parser("run", help="Payload-related operations")
    run_parser.add_argument("request_file")

    run_parser.add_argument("--base_url")

    run_parser.add_argument("--hide-length", "--hl", type=int)
    run_parser.add_argument("--show-length", "--sh", type=int)
    run_parser.add_argument("--show-code", "--sc", type=int, help="Show response code in the output")
    run_parser.add_argument("--hide-code", "--hc", type=int, help="Hide response code in the output")
    run_parser.add_argument("--show-string", "--ss", type=str, help="Show the string in the output")
    run_parser.add_argument("--hide-string", "--hs", type=str, help="Hide the string in the output")

    run_parser.add_argument("--script", action="append", help="Conditional scripts to run on the response")

    run_parser.add_argument("--https", action="store_true") # HTTP per default unless specified
        
    run_parser.add_argument("--time-based", action="store_true", help="Enable time-based guessing")
    run_parser.add_argument("--time-based-deviation", type=float, default=0.35, help="Deviation threshold for time-based guessing (default: 0.35)")
    run_parser.add_argument("--no-postprocess", "--npp", action="store_true") # HTTP per default unless specified

    run_parser.add_argument("--max-workers", type=int, default=MAX_WORKERS, help="Maximum number of concurrent workers (default: 10)")
    run_parser.add_argument("--max-concurrent-requests", type=int, default=MAX_CONCURRENT_REQUESTS, help="Maximum concurrent requests per token (default: 300)")

    run_parser.add_argument("--test-single", action="store_true", help="Test single request with the given parameters and print the response")

    run_parser.add_argument("--dry-run", "--dr", action="store_true", help="Dry run: show parsed parameters without executing requests")
    run_parser.add_argument("-v", action="store_true", help="Verbose mode: print more details")

    args = parser.parse_args()

    if args.max_workers:
        MAX_WORKERS = args.max_workers
        if VERBOSE:
            print(f"Setting max workers to {MAX_WORKERS}")

    if args.max_concurrent_requests:
        MAX_CONCURRENT_REQUESTS = args.max_concurrent_requests
        if VERBOSE:
            print(f"Setting max concurrent requests to {MAX_CONCURRENT_REQUESTS}")

    if args.v:
        VERBOSE = True

    if args.command == "run":
        if VERBOSE:
            print(f"Running with arguments: {args}")
            
        method, path, headers, body, base_url = parse_request_file(args.request_file)
        if not base_url and not args.base_url:
            raise ValueError("Host header not found in request.")
        else:
            if not args.base_url:
                if args.https:
                    args.base_url = f"https://{base_url}"
                else:
                    args.base_url = f"http://{base_url}"
        
        if not path.startswith('/'):
            path = '/' + path

        params = build_custom_parameters(method, path, headers, body, args)

        if args.no_postprocess:
            params['no_postprocess'] = True
            if VERBOSE:
                print("No post-processing enabled: responses will not be stored or analyzed.")

        if VERBOSE and not args.test_single:
            print(f"Parsed parameters: {json.dumps(params, indent=2)}")
        
        if args.dry_run:
            if not VERBOSE:
                print(f"Parsed parameters: {json.dumps(params, indent=2)}")

            print("Dry run mode: not executing requests.")
            return

        script_modules = []
        if args.script:
            for script_path in args.script:
                script_module = load_dynamic_script(script_path)
                if script_module:
                    print(f"Loaded dynamic script: {script_path}")
                    script_modules.append(script_module)
                else:
                    print(f"Failed to load dynamic script: {script_path}")
        params['script_modules'] = script_modules

        if args.test_single:
            # Test single request with the given parameters
            print("Testing single request with parameters:")

            # Get first word of the wordlist if available
            if 'FUZZ' in params and params['FUZZ']:
                for token in params['FUZZ']:
                    if token['mode'] == 'W' and 'wordlist' in token['options']:
                        wordlist_path = token['options']['wordlist']
                        if os.path.exists(wordlist_path):
                            with open(wordlist_path, 'r') as f:
                                first_word = f.readline().strip()
                                params['body'] = params['body'].replace(token['token'], first_word)
                                params['headers'] = {k: v.replace(token['token'], first_word) for k, v in params['headers'].items()}
                                params['path'] = params['path'].replace(token['token'], first_word)
                                
                    elif token['mode'] == 'I' and 'start' in token['options']:
                        # For integer tokens, replace with the start value
                        start_value = token['options'].get('start', '0')
                        params['body'] = params['body'].replace(token['token'], start_value)
                        params['headers'] = {k: v.replace(token['token'], start_value) for k, v in params['headers'].items()}
                        params['path'] = params['path'].replace(token['token'], start_value)

                    elif token['mode'] == 'G' and 'set' in token['options']:
                        # For character guessing tokens, replace with the first character of the set
                        charset = token['options'].get('set', 'alphanum')
                        first_char = charset[0] if charset else '?'
                        params['body'] = params['body'].replace(token['token'], first_char)
                        params['headers'] = {k: v.replace(token['token'], first_char) for k, v in params['headers'].items()}
                        params['path'] = params['path'].replace(token['token'], first_char)

            else:
                print("No FUZZ tokens found in parameters, using original body and headers.")
            filtered_params = {k: v for k, v in params.items() if k != 'script_modules'}

            print(json.dumps(filtered_params, indent=2))

            response = send_request(
                f"{params['base_url']}{params['path']}", params['method'], params['headers'], 
                params['body'], params['response_filters'], print_response=True,
            )
            print(f"Response: {json.dumps(response, indent=2)}")
            return
        
        result = fire_requests(params, time_based=args.time_based)
        if VERBOSE:
            print(f"Results: {json.dumps(result, indent=2)}")

if __name__ == "__main__":
    main()
